{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the required librares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.6)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.30.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (19.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting os-sys\n",
      "  Using cached os_sys-2.1.4-py3-none-any.whl (15.6 MB)\n",
      "Collecting pygubu (from os-sys)\n",
      "  Using cached pygubu-0.31-py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (2023.3)\n",
      "Collecting sqlparse (from os-sys)\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Collecting progress (from os-sys)\n",
      "  Using cached progress-1.6.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (4.65.0)\n",
      "Collecting progressbar (from os-sys)\n",
      "  Using cached progressbar-2.5.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (3.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (1.23.5)\n",
      "Requirement already satisfied: six in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (1.16.0)\n",
      "Collecting jupyter (from os-sys)\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (2.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from os-sys) (4.12.2)\n",
      "Collecting Eel (from os-sys)\n",
      "  Using cached Eel-0.16.0.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting extract-zip (from os-sys)\n",
      "  Using cached extract_zip-1.0.0-py3-none-any.whl (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting os-sys\n",
      "  Using cached os_sys-2.1.3-py3-none-any.whl (15.5 MB)\n",
      "  Using cached os_sys-2.1.2-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.1.1-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.1.0-py3-none-any.whl (15.9 MB)\n",
      "  Using cached os_sys-2.0.9-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.0.8-py3-none-any.whl (15.4 MB)\n",
      "  Using cached os_sys-2.0.7-py3-none-any.whl (14.2 MB)\n",
      "INFO: pip is looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached os_sys-2.0.6-py3-none-any.whl (14.2 MB)\n",
      "  Using cached os_sys-2.0.5-py3-none-any.whl (12.2 MB)\n",
      "  Using cached os_sys-2.0.4-py3-none-any.whl (50.9 MB)\n",
      "Collecting webview (from os-sys)\n",
      "  Using cached webview-0.1.5.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting os-sys\n",
      "  Using cached os_sys-2.0.3-py3-none-any.whl (51.8 MB)\n",
      "  Using cached os_sys-2.0.2-py3-none-any.whl (54.1 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached os_sys-2.0.1-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-2.0.0-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.9-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.8-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.7-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.6-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.5-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.4-py3-none-any.whl (54.1 MB)\n",
      "  Using cached os_sys-1.9.3-py3-none-any.whl (60.4 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: os-sys has an invalid wheel, os-sys has an invalid wheel, could not read 'os_sys-1.9.3.dist-info/WHEEL' file: KeyError(\"There is no item named 'os_sys-1.9.3.dist-info/WHEEL' in the archive\")\n"
     ]
    }
   ],
   "source": [
    "%pip install os-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we cannot display our openai api to everyone we need to hide it using dotenv "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so for this u need to hide .env file in your folder and write API_KEY = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "api_key  = os.getenv('API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the api is called in the program lets proceed further"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting started with openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust your settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"temperature\" setting in the OpenAI language model controls how creative and random the generated responses are.\n",
    "\n",
    "When the temperature is set to 0, the model provides very focused and predictable responses. So if you ask the same question multiple times, you will get the same or very similar answers each time.\n",
    "\n",
    "But when you increase the temperature above 0, like setting it to 1, the model becomes more creative and generates different responses for the same question. This randomness can be useful if you want more varied suggestions.\n",
    "\n",
    "The model tries to predict what text should come next based on the context. The temperature allows you to adjust how much the model relies on this prediction. Lowering the temperature makes the model more conservative, resulting in more accurate and expected responses. Raising the temperature makes the model more adventurous, leading to more diverse and unpredictable responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 .\n",
      "1)DeathCreediONaeFIstreamtw YRollinningDeadheepereii StreamNARghOLDlexCRASHCrashWaytiMle weAemaCTzonralCOLIRUFCSHcolhy5 GLplayCRUSH\n",
      "1. AdrenActiveLAtresiety \n",
      "2. RawPadrightCannon \n",
      "3. ActionaneousDeliverapaste \n",
      "4 HyperCaeryFilterTrainops\n",
      "5. ActionboxqKillEngine \n",
      "6 Fast\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "\n",
    "# Load the API key from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "# Set the API key for authentication with OpenAI\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Function to generate youtube channel name ideas\n",
    "def generate_youtube_channel_names(category, temperature=2):\n",
    "    prompt = f\"Generate youtube channel name ideas for {category}.\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Set the category for youtube channel names\n",
    "category = input(\"Enter your category\")\n",
    "\n",
    "# Generate pet name ideas\n",
    "for _ in range(3):\n",
    "    youtube_channel = generate_youtube_channel_names(category, temperature=2)\n",
    "    print(youtube_channel)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code u can change the temperature and check the changes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we process text using AI models, we break it down into smaller parts called tokens. Tokens can be individual words, parts of words, or even single characters. For example, the word \"cat\" is a token, and the name \"Butterscotch\" can be split into smaller tokens like \"But\", \"ters\", \"cot\", and \"ch\".\n",
    "\n",
    "The model then predicts which token is most likely to come next based on the input it receives. For instance, if the previous text is \"Horses are my favorite\", the model might predict that the next token could be \"animal\".\n",
    "\n",
    "Now, the concept of temperature comes into play. It helps control how creative or focused the model's predictions are. When the temperature is set to 0, the model will likely choose the token with the highest probability, resulting in more deterministic output. However, when the temperature is increased, the model becomes more adventurous and considers tokens with lower probabilities, resulting in more diverse and varied output.\n",
    "\n",
    "So, if you want the model to stick to more probable predictions, use a lower temperature. If you want more variety or creativity, use a higher temperature. It depends on the specific task or goal you have in mind."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your application"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the build application tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using OpenAI models, the cost is based on the number of tokens processed. Tokens are the individual units of text that the model reads and processes. For example, a word can be a token, or even a part of a word.\n",
    "There is a limit on the total number of tokens that can be processed in a single API request, usually around 4,096 tokens. This includes both the input prompt and the generated completion.\n",
    "The pricing is based on the number of tokens processed per 1,000 tokens. You pay for the tokens consumed by the model during the request.\n",
    "During the first 3 months, you also receive $5 in free credit, which you can use towards the cost of using the API.\n",
    "If you have more advanced tasks or need to provide more context or examples, the fine-tuning API allows you to customize the model using hundreds or thousands of examples specific to your use case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets go first with gpt-3.5 danvinci model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good afternoon everyone. \n",
      "\n",
      "I am delighted to be here today to talk about a revolutionary new technology gaining attention around the world: generative AI.\n",
      "\n",
      "Put simply, generative AI is a type of AI that is capable of learning from past data and then automatically creating new, useful data. It's a form of machine learning that works by taking data and analyzing it to generate new information that is useful in a wide variety of applications.\n",
      "\n",
      "One example of generative AI is natural language processing. Using algorithms and deep learning, generative AI can generate human-like language from existing data. This can be used to create original content from scratch or to augment a human-generated article.\n",
      "\n",
      "Generative AI is also being used to generate visual works of art. A generative AI program can study existing pieces of art and then create unique works based on this data.\n",
      "\n",
      "And generative AI can also be used to generate musical works. By analyzing a user's past musical tastes and preferences, generative AI can create custom soundtracks for any application.\n",
      "\n",
      "These are just a few examples of the incredible potential of generative AI. As this technology continues to evolve, its applications will only become more far-reaching and transformative.\n",
      "\n",
      "I am sure you can see that artificial intelligence has the power to not only make our lives easier, but to also help us create entirely new works of art or ideas that could not be produced by any single human being. \n",
      "\n",
      "Generative AI is an exciting breakthrough in the world of technology, and I am delighted that I can share it with you today.\n",
      "\n",
      "Thank you for your time.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "# Load the API key from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv('API_KEY')\n",
    "# Example: Using GPT-3.5 model\n",
    "def use_gpt35_turbo():\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',  # GPT-3.5 Turbo model\n",
    "        prompt='Write a speech on gernative ai.',\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "    print(generated_text)\n",
    "\n",
    "# Call the function to use GPT-3.5 Turbo model\n",
    "use_gpt35_turbo()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DALL·E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (20230314)\n",
      "Requirement already satisfied: numba in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (0.57.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (1.23.5)\n",
      "Requirement already satisfied: torch in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (2.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (9.1.0)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (0.3.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-whisper) (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken==0.3.1->openai-whisper) (2023.5.5)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken==0.3.1->openai-whisper) (2.30.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba->openai-whisper) (0.40.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->openai-whisper) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->openai-whisper) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.6)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.30.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (19.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow in c:\\users\\iamsn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U openai-whisper\n",
    "%pip install openai\n",
    "%pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
